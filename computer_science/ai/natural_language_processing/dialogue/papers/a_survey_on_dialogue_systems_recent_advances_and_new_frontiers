dialogue system
	task-oriented
	non-task-oriented

task-oriented
	Pipeline(管道) Methods
	End-to-End Methods(Neural Generative Models)

non-task-oriented
	Neural Generative Models
		seq2seq

	Retrieval-based Methods

Pipeline(管道) Methods
	The systems first understand the message given by human, represent(表示) it as an internal state;
	then take some actions according to the policy with respect to(关于) the dialogue state;  
	and finally, the action is transformed  to its surface form as a natural language.
	
	It consistes of four key components:
		Utterance(May I know your name) - NLU - DST - DPL - NLG - Utterance(I am Robot)
	
	NLU - Natural Language Understanding
		It is known as natural language understanding, which parses the user
		uterance into pre-defined semantic slots.

		Table-1
		Sentence	show	restaurant	at	New	York	tommorrow
		Slots		O	O		O	B-desti	I-desti	B-date
		Intent		Find Restaurant
		Domian		Order

		Give an utterance(言辞，言论), NLU maps it into sematic slots(语义槽),
		The slots are pre-defined according to different scenaries(场景).
		Typically, there are two level representations. 
			One is the word-level information extraction such as named entity recognition and slot filling. 
			(like scanning, lexical analysis, 词法分析)
			
			The other is the utterance(sentence 句子级别) level category,
			such as the user's intent and the utterance category.
			(like parsing, syntax analysis, gramatical analysis, 语法分析)

		Table-1 illustrates(说明，表明) an example of natural language representations,
		where "New York" as a splot values, and the domain and intent are slso specified, respectively.
		(其中，“New York”被认为是一个槽值(word-level), intent 和 domain 的值也会被指定(utterance level))

	DST - Dialogue State Tracking 
		It manages the input of each turn along with the dialogue history
		and outputs the current dialogue state.

		Tracking dialogue states is the core component to ensure a robust manner(健壮性) in dialog systems.
		It estimates(预测) the users goal at every turn of the dialogue, manage current input and dialogue history,
		and output dialogue state. This classic state structure is commonly called slot filling(槽填充) or semantic frame(语义框架).
		The traditional methods, which have been widely used in most commercial(商业的) implementations,
		often adopt(采用) hand-crafted(手工制作的) rules to select the most likely state.
		However, these rele-based systems are prone to(易于) frequent errors as the most result is not always the desired one.
	
	DPL - Dialogue Policy Learing  
		It learns the next action based on current dialogue state.

		Conditioned on the state representation from the state tracker,
		the policy learning is to generate the next availavle system action.
		Either supervised learning(监督学习) or reinforcement learning(强化xuexi)
		can be used to optimize(优化) policy learning. Then, supervised learning
		is conducted on(基于) the actions generated by the reles. In online shopping
		scenario, if the dialogue state is "Recommendation"(推荐), then the "Recommendation"
		action is triggered(触发), and the system will retrieve products from the product database.
		If the state is "Comparison", then the system will compare target products/brands.
		The dialogue policy can be further trained end-to-end with reinforcement learning
		to lead the system making policies toward the final performance.

	NLG - Natural Language Generation
		It maps the selected action to its surface and generates the response.

		The natural language generation component converts an abstract dialogue action
		into natural language surface utterances. A good generator usually relies on
		several factors: adequacy(适当), fluency, readability(可读) and variation(灵活).
		Conventional(传统的) approaches NLG typically perform sentence planning. It maps
		input semantic symbols into the intermeidary form representing the uttarance such as
		tree-like or template stuctures, and then converts the intermediate structure into
		the final response through the surface realizaion.

End-to-End Methods
	Because(Despite) a lot of domain-specific handcrafting in traditional task oriented dialogue systems,
	which are difficult to adapt to new domains. And the conventional pipeline of task-oriented dialogue systems
	has two limitaions. One is the credit assignment problem, where the end user's feedback(反馈)
	is hard to be propagated(传播, 影响) to each upstream module(后面模块很难修改前面模块的错误).
	The second issue is process interdependence(互相依赖). The input of a component is dependent on the
	output of another component. When adapting one component to new environment or retrained with new data,
	all the components need to be adapted accordingly to ensure a global optimization.
	Slots and features might change accordingly. This process requires significant human efforts.

	With the advance of end-to-end neural generative models in recent years, 
	many attempts have been made to construct(构建) an end-to-end trainable framework for task-oriented dialogue systems.
	Note that more details about neural generative models will be discussed when we introduce the non-taskoriented systems.
	A network-based end-to-end trainable task-oriented dialogue system,
	which treated dialogue system learning as the problem of learning
	a mapping from dialogue histories to system responses, and applied
	an encoder-decoder model to train the whole system.
	However, the system is trained in a supervised fashion - not only does
	it require a lot of training data, but it may also fail to find a good
	policy robustly due to the lack of exploration(探测) of dialogue control in the training data.

	Tasked-oriented systems usually need to query outside knowledge base.
	Previous systems achieved this by issuing a sysbolic query to the 
	knowledge base to retrive entries based on their attributes,
	where semantic parsing on the input is performed to construct a symbolic
	query representing the beliefs of the agent about the user goal.
	This approach has two drawbacks: the retrieved results do not carry any
	information about uncertainty in semantic parsing, and the retrieval
	operation is non differentiable(不可分割？), and hence(因此) the parser 
	and dialog policy are trained sperately.
